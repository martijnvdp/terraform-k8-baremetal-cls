#!/bin/bash
sudo swapoff -a
sudo sed -i '/swap/d' /etc/fstab
IFS== command eval  'release=($(cat /etc/os-release))'
if [[ $${release[1]} == *Ubuntu* ]];   
    then
        sudo ufw allow 6443
        sudo ufw allow 2379-2380
        sudo ufw allow 10250
        sudo ufw allow 10251
        sudo ufw allow 10252
        sudo ufw allow 10255
        sudo apt-get update
        sudo apt install sshpass -y
        sudo apt install python3 -y
        sudo apt install python3-pip -y
    else
        sudo firewall-cmd --permanent --add-port=6443/tcp
        sudo firewall-cmd --permanent --add-port=2379-2380/tcp
        sudo firewall-cmd --permanent --add-port=10250/tcp
        sudo firewall-cmd --permanent --add-port=10251/tcp
        sudo firewall-cmd --permanent --add-port=10252/tcp
        sudo firewall-cmd --permanent --add-port=10255/tcp
        sudo firewall-cmd --reload
        yum install sshpass -y
fi
pip3 uninstall ansible -y
pip3 uninstall ansible-base -y
pip3 install ansible==2.9.14
# version ansible 2.9.14 https://github.com/kubernetes-sigs/kubespray/issues/6762
pip3 install jinja2==2.11.1
pip3 install netaddr==0.7.19
pip3 install pbr==5.4.4
pip3 install jmespath==0.9.5
pip3 install ruamel.yaml==0.16.10
cd /tmp
sudo git clone https://github.com/kubernetes-sigs/kubespray.git
cd /tmp/kubespray
cp -rfp inventory/sample inventory/mycluster
CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${worker_nodes}
echo -e "  vars:\n    ansible_connection: ssh\n    ansible_user: ${admin_user}\n    ansible_ssh_pass: ${admin_pass}">> /tmp/kubespray/inventory/mycluster/hosts.yaml
echo -e "  localhost:\n   vars:\n    ansible_connection: local">> /tmp/kubespray/inventory/mycluster/hosts.yaml
sed -i 's/UserKnownHostsFile\=\/dev\/null/UserKnownHostsFile\=\/dev\/null -o IdentitiesOnly=yes/g' /tmp/kubespray/ansible.cfg
ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml
# initial config
cat <<EOF | sudo kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin
  namespace: default
EOF
# metallb
sudo kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/namespace.yaml
sudo kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/metallb.yaml
sudo kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)"
cat <<EOF | sudo kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - ${loadbalancer_iprange}
EOF
sudo kubeadm token list|sed '/TOKEN/d'| awk '{print $1}' > /tmp/token.txt
sudo kubectl describe secret $(sudo kubectl describe serviceaccount admin|grep Tokens:|awk '{print $2}') |grep token:|sed '/admin/g'|sed '/kubernetes/g'|awk '{print $2}' > /tmp/account-token
echo "token to use with scripts/add-cluster-to-local-config.sh :"
cat /tmp/account-token